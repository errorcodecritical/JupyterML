% Emerald Publishing - Construction Innovation Submission Template
% by Oleksandr Melnyk
% Ver 0.0.4
% Based on: https://www.emeraldgrouppublishing.com/journal/ci#author-guidelines

\documentclass{article}
\usepackage{booktabs}  % For professional tables
\usepackage{longtable} % For long tables that span multiple pages
\usepackage{adjustbox} % For text wrapping

\setlength{\parindent}{0pt}

\input{config/style}

\newcommand{\laplace}{\mathscr{L}}
\newcommand{\absolute}[1]{\left\lvert #1 \right\rvert}

\title{2025 ML Challenge Report \\ \textit{Room Occupancy Estimation using Machine Learning}}
\author[1]{Manuel F. Violas, Nº 2020221376}
\author[1]{Tobias M. Hulland, Nº 2021220300}
% \author[2]{Author Name 2}
\affil[1]{Universidade de Coimbra, Faculdade de Ciências e Tecnologia, Departamento de Engenharia Electrotécnica e de Computadores}
% \affil[2]{Institute, Department, City, Country}

\begin{document}
\begin{titlepage}
    \begin{figure}
        \centering
        \includegraphics[width=0.6\linewidth]{figures/FCTUC_H_FundoClaro.pdf}
    \end{figure}
    \maketitle
\end{titlepage}

\section*{Introduction: Room Occupancy Estimation Using Machine Learning}

As part of our Machine Learning course, we were tasked with identifying a problem, selecting a relevant dataset, and applying machine learning algorithms to address the issue.  
\\[\baselineskip]
Energy efficiency is a critical aspect of building management. Real-time room occupancy estimation can enable the development of intelligent, on-demand systems for heating, air conditioning, and lighting. Such systems not only improve energy consumption but also enhance occupant comfort.
\\[\baselineskip]
While computer vision systems for occupancy estimation exist, they are often expensive and require significant computational resources.  
\\[\baselineskip]
A more cost-effective and computationally efficient alternative involves using an array of affordable sensors (e.g., light, temperature, sound, motion, and \(CO_{2}\)). These sensors generate data that is less resource-intensive to process compared to camera-based systems.  
\begin{itemize}
    \item \textbf{Problem:} Inefficient energy usage in ventilation and lighting systems in buildings. Existing camera-based computer vision systems for room occupancy estimation are costly and computationally demanding.
    \item \textbf{Solution:} Transition from camera-based systems to sensor-based systems to reduce costs and computational resource requirements.
    \item \textbf{Objective:} The goal is to positively impact energy consumption in buildings by implementing efficient systems powered by machine learning algorithms.
\end{itemize}

The chosen dataset, \textit{Room Occupancy Estimation}, provides data on room occupancy and corresponding sensor readings over a specific period.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{figures/room_layout.png}
    \caption{Room Layout with Sensor Distribution}
    \label{fig:room_layout}
\end{figure}


Throughout this report, we will explore and analyze the \textit{Room Occupancy Dataset} and use it to train machine learning models for occupancy estimation.  


\section{Applying Exploratory Data Analysis on the Dataset}

\subsection{Understanding the Data}

The dataset utilized in this project was Room Occupancy Estimation, which consists of 10129 instances and 18 features (refer to table \ref{tab:sensor_data}). The data was collected every thirty seconds over four days in a controlled environment, where occupancy varied between 0 and 3 people.

\begin{table}[h!]
\centering
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{llll}
\toprule
\textbf{Feature/Target} & \textbf{Type} & \textbf{Description} & \textbf{Units} \\
\midrule
Date & Date & Date when the data was recorded & YYYY/MM/DD \\
Time & Time & Time when the data was recorded & HH:MM:SS \\
S1\_Temp - S4.Temp & Continuous & Ambient temperature measured at different sensor locations & °C \\
S1\_Light - S4.Light & Integer & Light intensity measured at different sensor locations & Lux \\
S1\_Sound - S4.Sound & Continuous & Sound levels measured using an amplifier output read by ADC & Volts \\
S5\_CO2 & Integer & Carbon dioxide (CO2) concentration in the room & PPM \\
S5\_CO2\_Slope & Continuous & Rate of change (slope) of CO2 concentration over time &  \\
S6\_PIR, S7\_PIR & Binary/Integer & Motion detection using Passive Infrared (PIR) sensors & (0 = No motion, 1 = Motion detected) \\
Room\_Occupancy\_Count & Integer & Ground truth number of occupants in the room &  \\
\bottomrule
\end{tabular}
\end{adjustbox}
\caption{Sensor Data Descriptions}
\label{tab:sensor_data}
\end{table}

\subsection{Data Balancing Check}
As a first step of processing the data, we assert if the data in question is balanced.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/target_distribution.png}
    \caption{Target Distribution - Number of Occupants}
    \label{fig:enter-label}
\end{figure}

We can clearly observe that the dataset is heavily unbalanced towards a single majority class of zero (0) occupants.
\\[\baselineskip]
We also observe that the dataset has no missing values.
\\[\baselineskip]
In this study, we explore various sampling techniques to determine which method yields the highest accuracy after training. Imbalanced datasets can affect model performance, leading to biased predictions. To mitigate this, we apply different oversampling and undersampling methods and compare their effects.

\subsection{Case Studies}
\begin{itemize}
    \item \textbf{Baseline} – No sampling method applied; used as a reference for comparison.
    \item \textbf{Oversampling Methods}
    \begin{itemize}
        \item \textbf{RandomOverSampler} – Duplicates random samples from the minority class.
        \item \textbf{SMOTE (Synthetic Minority Over-sampling Technique)} – Generates synthetic samples based on feature-space similarity.
        \item \textbf{ADASYN (Adaptive Synthetic Sampling)} – Similar to SMOTE but focuses more on harder-to-learn minority samples.
    \end{itemize}
    \item \textbf{Undersampling Methods}
    \begin{itemize}
        \item \textbf{RandomUnderSampler} – Randomly removes samples from the majority class.
        \item \textbf{NearMiss} – Selects majority class samples that are closest to the minority class.
        \item \textbf{CondensedNearestNeighbor} – Uses nearest-neighbor rules to reduce the dataset size while preserving decision boundaries.
    \end{itemize}
\end{itemize}

\subsection{Cleaning}
Second, we must assert that there are no duplicates in the dataset, removing any in order to prevent unwanted bias in our training, as well as removing any categorical or otherwise unquantifiable data.
\\[\baselineskip]
In this step, we disregard any temporal features, instead focusing purely on the acquired sensor data. This is because, according to the study data, measurements are taken every 30 seconds, making it impossible to remove duplicates otherwise.
\\[\baselineskip]
Upon counting the number of duplicates, we find that there are \textbf{1301} such rows in our dataset that are repeated. It is also important to note that these rows all contribute to the majority class and therefore removing them would help towards balancing our dataset.
\\[\baselineskip]
Finally, by removing all temporal data from our dataset, we are left with the following features:
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/feature_data.png}
    \caption{Numeric Feature Data}
    \label{fig:enter-label}
\end{figure}

Another thing we must consider is whether or not we should normalize our data. Since we specifically intend to use K-Nearest Neighbors in one of our approaches, we must first normalize the dataset.

\subsubsection{Data Normalization}
\begin{table}[h!]
\centering
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{lll}
\toprule
\textbf{Normalization Method} & \textbf{Features} & \textbf{Description} \\
\midrule
StandardScaler & S1\_Temp, S2\_Temp, S3\_Temp, S4\_Temp, S1\_Sound, S2\_Sound, S3\_Sound, S4\_Sound & Standardizes features by removing the mean and scaling to unit variance. \\
MinMaxScaler & S1\_Light, S2\_Light, S3\_Light, S4\_Light & Scales features to a given range, typically [0, 1]. \\
RobustScaler & S5\_C02, S5\_C02\_Slope & Scales features using statistics that are robust to outliers. \\
None & S6\_PIR, S7\_PIR & No standardization necessary as the data is already constrained to [0, 1]. \\
\bottomrule
\end{tabular}
\end{adjustbox}
\caption{Normalization Methods Applied to Features}
\label{tab:normalization_methods}
\end{table}

Different features have different distributions, therefore some normalization methods are more suited than others. In the case of our dataset's features, table \ref{tab:normalization_methods} lists which scalers were used on which features.

\subsection{Univariate Analysis (Single Feature)}

\subsubsection{Date}
\textit{Date} is an identifier of what day the measurement was made. Since all data was recovered over the span of a few weeks with controlled conditions, this column has little relevance on the output in this case therefore is not worth studying.

\subsubsection{Time} 
\textit{Time} represents the time of day to which the entry is relative to. The measurements were taken over the period of four days every thirty seconds. 
\\[\baselineskip]
While it is possible to remap this feature as a continuous variable, we intend only to study the sensor data as opposed to the behavioral patterns of the room occupants, because we find it more relevant to the objective.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/time_of_day_feature_dist.png}
    \caption{Time of Day Feature Distribution}
    \label{fig:enter-label}
\end{figure}

\subsubsection{Temperature}
There are four (4) temperature sensors in total distributed across the studied room. The aggregate data is as follows:
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/temp_feature_dist.png}
    \caption{Temperature Feature Distributions}
    \label{fig:enter-label}
 \end{figure}

\subsubsection{Light}
There are four (4) light sensors in total distributed across the studied room. The aggregate data is as follows:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/light_feature_dist.png}
    \caption{Light Feature Distributions}
    \label{fig:enter-label}
\end{figure}

\subsubsection{Sound}
There are four (4) sound sensors in total distributed across the studied room. The aggregate data is as follows:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/sound_feature_dist.png}
    \caption{Sound Feature Distributions}
    \label{fig:enter-label}
\end{figure}

\subsubsection{Carbon Dioxide}
There is (1) CO2 sensor in total located in the studied room. The aggregate data is as follows:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/co2_feature_dist.png}
    \caption{CO2 Feature Distributions}
    \label{fig:enter-label}
\end{figure}

\subsubsection{Passive Infrared}
There are two (2) PIR sensors in total distributed across the studied room. The aggregate data is as follows:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/pir_feature_dist.png}
    \caption{PIR Feature Distributions}
    \label{fig:enter-label}
\end{figure}


 Below we show two tables with the relevant metrics associated with each sensor.

 

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/classification_mean.png}
    \caption{Mean by Classification}
    \label{tab:Mean by classification}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/clasification_std.png}
    \caption{Standard deviation by Classification}
    \label{tab:Standard deviation by classification}
\end{figure}

\subsection{Multivariate Analysis (Feature Relationships)}
\subsubsection{Correlation Matrix}
The correlation matrix allows us to visualize the relationship between each of our features and our target, identifying higher correlation the greater the value displayed, and lower the closer the value is to zero (0).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/correlation_heatmap.png}
    \caption{Correlation Heatmap of Sensor Features}
    \label{fig:enter-label}
\end{figure}

Upon inspection, we can immediately tell there is a strong relationship between the Occupancy with the Light features, slightly less correlation with the Temperature, $CO_{2}$ and PIR features, and lowest correlation with the Sound features.

\subsubsection{Pairplot Visualization}
Like the Correlation Matrix, the pairplot lets us analyze the features' relationships with the target, helping us to spot linear relationships, clusters and outliers.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/pairplot.png}
    \caption{Pairplot Graph}
    \label{fig:enter-label}
\end{figure}


% \subsection{Feature Engineering (For Time Inclusion)}

\subsection{Feature Selection}

We decided to utilize various correlation thresholds to test which features can be disregarded without sacrificing accuracy of the model.
\\[\baselineskip]
To this end, each case study to be performed shall be tested with three different threshold values. 
\\[\baselineskip]
The correlation threshold values chosen are \textbf{[0.0, 0.5, 0.8]}, whereby a greater value signifies greater correlation.
 
\section{Training the Models}

    We decided to utilize three different training models: Decision Tree Classifier, K Nearest Neighbours and Naive Bayes.

    \subsection{Adjusting parameters}

    We utilized GridSearch CV in order to maximize the efficiency of our DTC and KNN models. 

    \subsection{Train-Test split}

    When training the models we employed a 75-25 train-test split. This was an arbitrarily chosen number in the end since any other split seemed to have very similar accuracies (even absurd values such as 5-95 resulted in mere tenths of a percent differences in accuracy scores in most models).

\section{Results and Conclusions}

\begin{table}[h!]
\centering
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{cccccccccc}
\toprule
\textbf{Index} & \textbf{Sampling Method} & \textbf{Sampling Method} & \textbf{Classifier} & \textbf{Train Accuracy} & \textbf{Test Accuracy} & \textbf{F1-Score} & \textbf{Recall} & \textbf{Precision} & \textbf{Parameters} \\
\midrule
0 & Baseline & DTC & 0\% & 1.000000 & 0.995469 & 0.995463 & 0.995469 & 0.995487 & [criterion: entropy, max\_depth: 20, min\_samples\_leaf: 1, min\_samples\_split: 2] \\
1 & Baseline & DTC & 50\% & 1.000000 & 0.994110 & 0.994098 & 0.994110 & 0.994137 & [criterion: entropy, max\_depth: None, min\_samples\_leaf: 1, min\_samples\_split: 2] \\
2 & Baseline & DTC & 80\% & 0.999849 & 0.997281 & 0.997279 & 0.997281 & 0.997280 & [criterion: entropy, max\_depth: None, min\_samples\_leaf: 1, min\_samples\_split: 2] \\
3 & RandomOversampler & DTC & 0\% & 1.000000 & 0.999856 & 0.999856 & 0.999856 & 0.999856 & [criterion: gini, max\_depth: None, min\_samples\_leaf: 1, min\_samples\_split: 5] \\
4 & RandomOversampler & DTC & 50\% & 0.999952 & 0.999567 & 0.999567 & 0.999567 & 0.999568 & [criterion: entropy, max\_depth: None, min\_samples\_leaf: 1, min\_samples\_split: 10] \\
5 & SMOTE & DTC & 0\% & 0.999759 & 0.997113 & 0.997112 & 0.997113 & 0.997115 & [criterion: entropy, max\_depth: None, min\_samples\_leaf: 1, min\_samples\_split: 5] \\
6 & SMOTE & DTC & 50\% & 1.000000 & 0.996535 & 0.996537 & 0.996535 & 0.996542 & [criterion: entropy, max\_depth: None, min\_samples\_leaf: 1, min\_samples\_split: 2] \\
7 & SMOTENC & DTC & 0\% & 1.000000 & 0.996968 & 0.996968 & 0.996968 & 0.996969 & [criterion: entropy, max\_depth: 20, min\_samples\_leaf: 1, min\_samples\_split: 2] \\
8 & SMOTENC & DTC & 50\% & 0.999759 & 0.996680 & 0.996680 & 0.996680 & 0.996680 & [criterion: entropy, max\_depth: 20, min\_samples\_leaf: 1, min\_samples\_split: 5] \\
9 & RandomUndersampler & DTC & 0\% & 0.998548 & 0.984749 & 0.984748 & 0.984749 & 0.985087 & [criterion: entropy, max\_depth: 10, min\_samples\_leaf: 1, min\_samples\_split: 2] \\
10 & RandomUndersampler & DTC & 50\% & 0.997821 & 0.980392 & 0.980517 & 0.980392 & 0.981126 & [criterion: entropy, max\_depth: 10, min\_samples\_leaf: 1, min\_samples\_split: 5] \\
11 & NearMiss & DTC & 0\% & 0.990559 & 0.984749 & 0.984749 & 0.984749 & 0.984676 & [criterion: entropy, max\_depth: 5, min\_samples\_leaf: 5, min\_samples\_split: 10] \\
12 & NearMiss & DTC & 50\% & 0.992738 & 0.982571 & 0.982606 & 0.982571 & 0.982722 & [criterion: entropy, max\_depth: 5, min\_samples\_leaf: 1, min\_samples\_split: 2] \\
13 & CondensedNearestNeighbour & DTC & 0\% & 1.000000 & 0.937853 & 0.941784 & 0.937853 & 0.949405 & [criterion: gini, max\_depth: None, min\_samples\_leaf: 1, min\_samples\_split: 2] \\
14 & CondensedNearestNeighbour & DTC & 50\% & 0.994340 & 0.96102 & 0.96704 & 0.96102 & 0.967514 & [criterion: entropy, max\_depth: 10, min\_samples\_leaf: 1, min\_samples\_split: 10] \\
15 & Baseline & KNN & 0\% & 1.000000 & 0.987766 & 0.987759 & 0.987766 & 0.987783 & [metric: manhattan, n\_neighbors: 3, weights: distance] \\
16 & Baseline & KNN & 50\% & 1.000000 & 0.987766 & 0.987759 & 0.987766 & 0.987783 & [metric: manhattan, n\_neighbors: 3, weights: distance] \\
17 & Baseline & KNN & 80\% & 0.999849 & 0.997281 & 0.997281 & 0.997281 & 0.997281 & [metric: manhattan, n\_neighbors: 5, weights: distance] \\
18 & RandomOversampler & KNN & 0\% & 1.000000 & 0.999711 & 0.999711 & 0.999711 & 0.999712 & [metric: manhattan, n\_neighbors: 3, weights: distance] \\
19 & RandomOversampler & KNN & 50\% & 1.000000 & 0.999423 & 0.999423 & 0.999423 & 0.999424 & [metric: manhattan, n\_neighbors: 3, weights: distance] \\
20 & SMOTE & KNN & 0\% & 1.000000 & 0.998412 & 0.998413 & 0.998412 & 0.998415 & [metric: manhattan, n\_neighbors: 3, weights: distance] \\
21 & SMOTE & KNN & 50\% & 1.000000 & 0.997979 & 0.997979 & 0.997979 & 0.997981 & [metric: manhattan, n\_neighbors: 3, weights: distance] \\
22 & SMOTENC & KNN & 0\% & 1.000000 & 0.998845 & 0.998845 & 0.998845 & 0.998847 & [metric: manhattan, n\_neighbors: 3, weights: distance] \\
23 & SMOTENC & KNN & 50\% & 1.000000 & 0.997979 & 0.997980 & 0.997979 & 0.997983 & [metric: manhattan, n\_neighbors: 3, weights: distance] \\
24 & RandomUndersampler & KNN & 0\% & 1.000000 & 0.958606 & 0.958726 & 0.958606 & 0.960235 & [metric: manhattan, n\_neighbors: 3, weights: distance] \\
25 & RandomUndersampler & KNN & 50\% & 1.000000 & 0.952070 & 0.952150 & 0.952070 & 0.952924 & [metric: manhattan, n\_neighbors: 3, weights: distance] \\
26 & NearMiss & KNN & 0\% & 1.000000 & 0.971678 & 0.971779 & 0.971678 & 0.972396 & [metric: manhattan, n\_neighbors: 3, weights: distance] \\
27 & NearMiss & KNN & 50\% & 1.000000 & 0.982571 & 0.982616 & 0.982571 & 0.982742 & [metric: manhattan, n\_neighbors: 5, weights: distance] \\
28 & CondensedNearestNeighbour & KNN & 0\% & 1.000000 & 0.830508 & 0.819674 & 0.830508 & 0.819537 & [metric: manhattan, n\_neighbors: 3, weights: distance] \\
29 & CondensedNearestNeighbour & KNN & 50\% & 1.000000 & 0.994350 & 0.994424 & 0.994350 & 0.994821 & [metric: manhattan, n\_neighbors: 5, weights: distance] \\
\bottomrule
\end{tabular}
\end{adjustbox}
\caption{Classifier Performance Metrics}
\label{tab:classifier_performance}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/test_results.png}
    \caption{Classifier Performance Metrics}
    \label{fig:enter-label}
\end{figure}

\begin{thebibliography}{9}
\bibitem{control}
K. Ogata, \emph{Modern Control Engineering}, 5th Edition, Prentice Hall, 2010.
\end{thebibliography}

\end{document}
