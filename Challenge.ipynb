{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Room Occupancy Estimation using Machine Learning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook aims to analyze and develop machine learning models for **Room Occupancy Estimation** using non-intrusive environmental sensors such as **temperature, light, sound, CO2, and PIR (Passive Infrared)**. The goal is to predict the number of occupants in a room based on sensor data.\n",
    "\n",
    "This project is developed as part of the **Machine Learning Challenge (Aprendizagem Computacional), 2025** at **DEI, FCT, University of Coimbra**. The objective of the challenge is to identify a real-world classification problem, apply simple machine learning grid_grid_grid_grid_grid_grid_grid_models, and evaluate their effectiveness.\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "The dataset used in this project is [**Room Occupancy Estimation**](https://archive.ics.uci.edu/dataset/864/room+occupancy+estimation), which consists of **10129 instances and 18 features**. The data was collected over four days in a controlled environment, where occupancy varied between **0 and 3 people**.\n",
    "\n",
    "- **Sensor Types Used:**\n",
    "  - **Temperature**\n",
    "  - **Light**\n",
    "  - **Sound**\n",
    "  - **CO2**\n",
    "  - **Passive Infrared (PIR)**\n",
    "\n",
    "- **Experimental Setup:**\n",
    "  - Data was collected in a **6m x 4.6m room**.\n",
    "  - **7 sensor nodes** were deployed, transmitting data every **30 seconds**.\n",
    "  - The PIR, CO2, and sound sensors required manual calibration.\n",
    "  - The ground truth was manually recorded.\n",
    "\n",
    "## Challenge Goals\n",
    "\n",
    "The primary goals of this challenge are:\n",
    "1. **Problem Identification:** Understand how environmental sensor data can be used for room occupancy estimation.\n",
    "2. **Data Analysis:** Explore the dataset, clean, and preprocess it.\n",
    "3. **Model Construction:** Implement at least **two simple machine learning models** (e.g., Decision Trees, K-Nearest Neighbors, Logistic Regression).\n",
    "4. **Evaluation Metrics:** Assess model performance using appropriate evaluation metrics.\n",
    "5. **Documentation & Submission:** Record findings, methodologies, and challenges faced.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Load and preprocess the dataset.\n",
    "2. Perform exploratory data analysis (EDA).\n",
    "3. Train and evaluate machine learning models.\n",
    "4. Compare model performance using visualization tools.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Column Descriptions\n",
    "| **Feature/Target**    | **Type**       | **Description**                                              | **Units**      |\n",
    "|-------------------------|---------------|--------------------------------------------------------------|---------------|\n",
    "| `Date`                 | Date          | Date when the data was recorded                              | YYYY/MM/DD    |\n",
    "| `Time`                 | Time          | Time when the data was recorded                              | HH:MM:SS      |\n",
    "| `S1_Temp` – `S4_Temp`  | Continuous    | Ambient temperature measured at different sensor locations   | °C            |\n",
    "| `S1_Light` – `S4_Light`| Integer       | Light intensity measured at different sensor locations       | Lux           |\n",
    "| `S1_Sound` – `S4_Sound`| Continuous    | Sound levels measured using an amplifier output read by ADC  | Volts         |\n",
    "| `S5_CO2`              | Integer       | Carbon dioxide (CO2) concentration in the room              | PPM           |\n",
    "| `S5_CO2_Slope`       | Continuous    | Rate of change (slope) of CO2 concentration over time       | -             |\n",
    "| `S6_PIR`, `S7_PIR`    | Binary/Integer | Motion detection using Passive Infrared (PIR) sensors       | - (0 = No motion, 1 = Motion detected) |\n",
    "| `Room_Occupancy_Count` | Integer        | Ground truth number of occupants in the room                | -             |\n",
    "\n",
    "\n",
    "**NOTE:** There are no missing (null) values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Required Libs: pip install scikit-learn pandas numpy scipy matplotlib seaborn\n",
    "\n",
    "For report:\n",
    "- DETERMINE PROBLEM, SOLUTION, OBJECTIVE;\n",
    "- BREAKDOWN OF THE DATASET, DESCRIPTION OF VARIABLES AND TARGETS, NUMBER OF NULL VALUES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "#Converts hours, minutes, seconds to seconds for easier handling\n",
    "\n",
    "def hms_to_seconds(t):\n",
    "    h, m, s = [int(i) for i in str(t).split(':')]\n",
    "    return 3600*h + 60*m + s\n",
    "  \n",
    "# fetch dataset \n",
    "room_occupancy_estimation = fetch_ucirepo(id=864) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = room_occupancy_estimation.data.features\n",
    "y = room_occupancy_estimation.data.targets\n",
    "\n",
    "# Get number of target elements of the same category\n",
    "target_distribution = y.pivot_table(index=[\"Room_Occupancy_Count\"], aggfunc=\"size\")\n",
    "print(target_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of data entries\n",
    "X.join(y).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set a theme for Seaborn plots\n",
    "sns.set_theme()\n",
    "\n",
    "# Histogram of \"Room_Occupancy_Count\"\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=[\"0\", \"1\", \"2\", \"3\"], y=target_distribution.values)\n",
    "plt.title(\"Room Occupancy Distribution\")\n",
    "plt.xlabel(\"Number of Occupants\")\n",
    "plt.ylabel(\"Occurences\")\n",
    "plt.show()\n",
    "\n",
    "# We can see the dataset is unbalanced. Ruh-roh!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA - Exploration Data Analysis\n",
    "\n",
    "1. Remove rows with missing data - since there are no null values in the dataset, this step can be skipped.\n",
    "2. Remove duplicate rows. Notice how the duplicate data is (mostly) constrained to late night / early mornings when the room is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of strictly numeric feature names\n",
    "numeric_features = X.select_dtypes(include=\"number\").columns.tolist()\n",
    "\n",
    "# Count and remove duplicates\n",
    "mask_duplicates = X.duplicated(subset=numeric_features, keep=\"first\")\n",
    "count_duplicates = mask_duplicates.sum()\n",
    "\n",
    "print(count_duplicates)\n",
    "\n",
    "X1 = X.drop_duplicates(subset=numeric_features).select_dtypes(include=\"number\")\n",
    "y1 = y[~mask_duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated \"Room_Occupancy_Count\" after removing duplicates\n",
    "target_distribution = y1.pivot_table(index=[\"Room_Occupancy_Count\"], aggfunc=\"size\")\n",
    "\n",
    "print(target_distribution)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=[\"0\", \"1\", \"2\", \"3\"], y=target_distribution.values)\n",
    "plt.title(\"Room Occupancy Distribution\")\n",
    "plt.xlabel(\"Number of Occupants\")\n",
    "plt.ylabel(\"Occurences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"DateTime\"] = pd.to_datetime(X[\"Date\"] + \" \" + X[\"Time\"])\n",
    "X[\"Hour\"] = X[\"DateTime\"].dt.hour\n",
    "\n",
    "# Plot occupancy by hour\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x=X[\"Hour\"], y=y[\"Room_Occupancy_Count\"], palette=\"coolwarm\")\n",
    "plt.title(\"Occupancy Count by Hour of the Day\")\n",
    "plt.xlabel(\"Hour of the Day\")\n",
    "plt.ylabel(\"Occupancy Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouped Univariate Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping sensor variables\n",
    "sensor_groups = {\n",
    "    \"Temperature (°C)\": [\"S1_Temp\", \"S2_Temp\", \"S3_Temp\", \"S4_Temp\"],\n",
    "    \"Light (Lux)\": [\"S1_Light\", \"S2_Light\", \"S3_Light\", \"S4_Light\"],\n",
    "    \"Sound (Volts)\": [\"S1_Sound\", \"S2_Sound\", \"S3_Sound\", \"S4_Sound\"],\n",
    "    \"CO2 (PPM)\": [\"S5_CO2\", \"S5_CO2_Slope\"],\n",
    "}\n",
    "\n",
    "# Plot continuous variables with KDE plots\n",
    "fig, axes = plt.subplots(len(sensor_groups) + 1, 1, figsize=(10, 18))  # Extra subplot for PIR\n",
    "for ax, (group_name, features) in zip(axes[:-1], sensor_groups.items()):\n",
    "    for feature in features:\n",
    "        sns.kdeplot(X1[feature], ax=ax, label=feature, fill=True, alpha=0.4)\n",
    "    \n",
    "    ax.set_title(f\"{group_name} Distribution\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "\n",
    "# Separate plot for PIR Motion (binary data) using bar plots\n",
    "ax_pir = axes[-1]\n",
    "pir_data = X1[[\"S6_PIR\", \"S7_PIR\"]].melt(var_name=\"Sensor\", value_name=\"Value\")\n",
    "sns.countplot(x=\"Value\", hue=\"Sensor\", data=pir_data, ax=ax_pir)\n",
    "\n",
    "ax_pir.set_title(\"PIR Motion Detection Counts\")\n",
    "ax_pir.set_xlabel(\"Motion Detected (0 = No, 1 = Yes)\")\n",
    "ax_pir.set_ylabel(\"Count\")\n",
    "ax_pir.legend(title=\"Sensor\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1y1 = X1.join(y1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(X1y1.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X1y1.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now study different sampling methods in order to determine the method that provides the most accuracy after training.\n",
    "\n",
    "## Case studies:\n",
    "- Baseline (no sampling method applied)\n",
    "- Oversampling\n",
    "    - RandomOverSampler\n",
    "    - SMOTE\n",
    "    - ADASYN\n",
    "- Undersampling\n",
    "    - RandomUnderSampler\n",
    "    - NearMiss\n",
    "    - CondensedNearestNeighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1_Temp</th>\n",
       "      <th>S2_Temp</th>\n",
       "      <th>S3_Temp</th>\n",
       "      <th>S4_Temp</th>\n",
       "      <th>S1_Light</th>\n",
       "      <th>S2_Light</th>\n",
       "      <th>S3_Light</th>\n",
       "      <th>S4_Light</th>\n",
       "      <th>S1_Sound</th>\n",
       "      <th>S2_Sound</th>\n",
       "      <th>S3_Sound</th>\n",
       "      <th>S4_Sound</th>\n",
       "      <th>S5_CO2</th>\n",
       "      <th>S5_CO2_Slope</th>\n",
       "      <th>S6_PIR</th>\n",
       "      <th>S7_PIR</th>\n",
       "      <th>Room_Occupancy_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.484283</td>\n",
       "      <td>-1.359085</td>\n",
       "      <td>-1.215903</td>\n",
       "      <td>-1.131861</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.131783</td>\n",
       "      <td>0.189286</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>-0.302849</td>\n",
       "      <td>0.209158</td>\n",
       "      <td>-0.255726</td>\n",
       "      <td>-0.363976</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6.451613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.484283</td>\n",
       "      <td>-1.359085</td>\n",
       "      <td>-1.215903</td>\n",
       "      <td>-0.964796</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0.189286</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>2.219398</td>\n",
       "      <td>-0.283932</td>\n",
       "      <td>-0.255726</td>\n",
       "      <td>-0.363976</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5.419355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.320182</td>\n",
       "      <td>-1.359085</td>\n",
       "      <td>-1.352076</td>\n",
       "      <td>-0.964796</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.131783</td>\n",
       "      <td>0.189286</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.735723</td>\n",
       "      <td>-0.072608</td>\n",
       "      <td>-0.210389</td>\n",
       "      <td>-0.363976</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4.354839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.320182</td>\n",
       "      <td>-1.359085</td>\n",
       "      <td>-1.215903</td>\n",
       "      <td>-0.964796</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.131783</td>\n",
       "      <td>0.189286</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.676376</td>\n",
       "      <td>-0.107828</td>\n",
       "      <td>-0.165052</td>\n",
       "      <td>-0.131126</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.258065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.320182</td>\n",
       "      <td>-1.359085</td>\n",
       "      <td>-1.215903</td>\n",
       "      <td>-0.964796</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.131783</td>\n",
       "      <td>0.192857</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>-0.006114</td>\n",
       "      <td>-0.248711</td>\n",
       "      <td>-0.255726</td>\n",
       "      <td>-0.363976</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2.129032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>-1.156082</td>\n",
       "      <td>-0.742247</td>\n",
       "      <td>-0.920862</td>\n",
       "      <td>-1.326769</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.027132</td>\n",
       "      <td>0.117857</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>-0.273176</td>\n",
       "      <td>-0.319153</td>\n",
       "      <td>-0.255726</td>\n",
       "      <td>-0.208743</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10125</th>\n",
       "      <td>-1.156082</td>\n",
       "      <td>-0.855875</td>\n",
       "      <td>-0.920862</td>\n",
       "      <td>-1.493834</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.027132</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>-0.332523</td>\n",
       "      <td>-0.283932</td>\n",
       "      <td>-0.278394</td>\n",
       "      <td>-0.208743</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>-0.964631</td>\n",
       "      <td>-0.855875</td>\n",
       "      <td>-0.920862</td>\n",
       "      <td>-1.493834</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.027132</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>-0.213829</td>\n",
       "      <td>-0.283932</td>\n",
       "      <td>-0.255726</td>\n",
       "      <td>-0.208743</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10127</th>\n",
       "      <td>-0.964631</td>\n",
       "      <td>-0.855875</td>\n",
       "      <td>-0.920862</td>\n",
       "      <td>-1.493834</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.027132</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>-0.302849</td>\n",
       "      <td>-0.178270</td>\n",
       "      <td>-0.165052</td>\n",
       "      <td>-0.208743</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10128</th>\n",
       "      <td>-0.964631</td>\n",
       "      <td>-0.855875</td>\n",
       "      <td>-0.920862</td>\n",
       "      <td>-1.493834</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.027132</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>-0.302849</td>\n",
       "      <td>-0.283932</td>\n",
       "      <td>-0.255726</td>\n",
       "      <td>-0.208743</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8828 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        S1_Temp   S2_Temp   S3_Temp  ...  S6_PIR  S7_PIR  Room_Occupancy_Count\n",
       "0     -1.484283 -1.359085 -1.215903  ...       0       0                     1\n",
       "1     -1.484283 -1.359085 -1.215903  ...       0       0                     1\n",
       "2     -1.320182 -1.359085 -1.352076  ...       0       0                     1\n",
       "3     -1.320182 -1.359085 -1.215903  ...       0       0                     1\n",
       "4     -1.320182 -1.359085 -1.215903  ...       0       0                     1\n",
       "...         ...       ...       ...  ...     ...     ...                   ...\n",
       "10124 -1.156082 -0.742247 -0.920862  ...       0       0                     0\n",
       "10125 -1.156082 -0.855875 -0.920862  ...       0       0                     0\n",
       "10126 -0.964631 -0.855875 -0.920862  ...       0       0                     0\n",
       "10127 -0.964631 -0.855875 -0.920862  ...       0       0                     0\n",
       "10128 -0.964631 -0.855875 -0.920862  ...       0       0                     0\n",
       "\n",
       "[8828 rows x 17 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "X2y2 = X1y1.copy()\n",
    "\n",
    "# Standardize Temperature & Sound\n",
    "std_scaler = StandardScaler()\n",
    "std_features = ['S1_Temp', 'S2_Temp', 'S3_Temp', 'S4_Temp', 'S1_Sound', 'S2_Sound', 'S3_Sound', 'S4_Sound']\n",
    "X2y2[std_features] = std_scaler.fit_transform(X1y1[std_features])\n",
    "\n",
    "# Min-Max Scale Light sensors\n",
    "minmax_scaler = MinMaxScaler()\n",
    "minmax_features = ['S1_Light', 'S2_Light', 'S3_Light', 'S4_Light']\n",
    "X2y2[minmax_features] = minmax_scaler.fit_transform(X1y1[minmax_features])\n",
    "\n",
    "# Robust Scale CO2 & CO2 Slope\n",
    "robust_scaler = RobustScaler()\n",
    "robust_features = ['S5_CO2', 'S5_CO2_Slope']\n",
    "X2y2[robust_features] = robust_scaler.fit_transform(X1y1[robust_features])\n",
    "\n",
    "# No standardization necessary for PIR sensor data, since it is already constrained [0, 1]\n",
    "\n",
    "X2y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss, CondensedNearestNeighbour\n",
    "\n",
    "X2 = X2y2.drop(columns=[\"Room_Occupancy_Count\"])\n",
    "y2 = X2y2[[\"Room_Occupancy_Count\"]]\n",
    "\n",
    "sampler_tests = {}\n",
    "\n",
    "# Baseline\n",
    "sampler_tests[\"Baseline\"] = [X2, y2]\n",
    "\n",
    "# RandomOverSampler\n",
    "sampler = RandomOverSampler(sampling_strategy=\"auto\", random_state=42)\n",
    "sampler_tests[\"RandomOverSampler\"] = sampler.fit_resample(X2, y2)\n",
    "\n",
    "# SMOTE\n",
    "sampler = SMOTE(sampling_strategy=\"auto\", random_state=42)\n",
    "sampler_tests[\"SMOTE\"] = sampler.fit_resample(X2, y2)\n",
    "\n",
    "# SMOTENC - Categorical features [S6_PIR, S7_PIR]\n",
    "sampler = SMOTENC(sampling_strategy=\"auto\", random_state=42, categorical_features=[14, 15])\n",
    "sampler_tests[\"SMOTENC\"] = sampler.fit_resample(X2, y2)\n",
    "\n",
    "# RandomUnderSampler\n",
    "sampler = RandomUnderSampler(sampling_strategy=\"auto\", random_state=42)\n",
    "sampler_tests[\"RandomUnderSampler\"] = sampler.fit_resample(X2, y2)\n",
    "\n",
    "# NearMiss\n",
    "sampler = NearMiss(sampling_strategy=\"auto\")\n",
    "sampler_tests[\"NearMiss\"] = sampler.fit_resample(X2, y2)\n",
    "\n",
    "# CondensedNearestNeighbour\n",
    "sampler = CondensedNearestNeighbour(sampling_strategy=\"auto\", random_state=42)\n",
    "sampler_tests[\"CondensedNearestNeighbour\"] = sampler.fit_resample(X2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating data\n",
    "\n",
    "- Removal of columns with lower correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each sampling method, perform tests with different correlation thresholds to determine which features can be disregarded\n",
    "\n",
    "test_thresholds = [0.00, 0.50, 0.8]\n",
    "\n",
    "test_data = []\n",
    "\n",
    "for test_method, (X3, y3) in sampler_tests.items():\n",
    "    for threshold in test_thresholds:\n",
    "        X3y3 = X3.join(y3)\n",
    "        corr_matrix = X3y3.corr()\n",
    "\n",
    "        # Find features that have at least one correlation above the threshold (excluding the diagonal); abs() is used to find most and least correlated features.\n",
    "        correlated_features = corr_matrix.abs().columns[(corr_matrix > threshold).sum() > 1]\n",
    "\n",
    "        # If there is no correlation between the features and our target, then the target won't appear in the list. We can ignore this test.\n",
    "        if correlated_features.to_list().count(\"Room_Occupancy_Count\") == 0:\n",
    "            continue\n",
    "\n",
    "        X4y4 = X3y3[correlated_features]\n",
    "        \n",
    "        test_data.append({\n",
    "            \"method\": test_method,\n",
    "            \"threshold\": threshold,\n",
    "            \"features\": correlated_features,\n",
    "            \"data\": X4y4\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also represent the data with a pairplot in order to better visualize the distribution of dataset samples, which can be useful to later establish a correlation threshold\n",
    "\n",
    "# For representation purposes, we can reduce the number of datapoints by random sampling.\n",
    "# X2y2_subsampled = X2y2.sample(frac=0.1, random_state=42)  # Take 10% of the data.\n",
    "\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# sns.pairplot(X2y2, hue=\"Room_Occupancy_Count\", diag_kind=\"hist\", palette=\"coolwarm\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "for data in test_data:\n",
    "    display(data[\"data\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now normalize the data as is required for our model training method (KNN), even though this is unnecessary for methods like decision trees. **(ChatGPT was used to help select the best normalization technique based on the dataset summary)**:\n",
    "- Temperature values (S1_Temp to S4_Temp):\n",
    "    - Mean is around 25-26°C with a small standard deviation (~0.3 - 0.8).\n",
    "    - The range is small (around 24.9 to 29.0).\n",
    "    - Standardization (Z-score) would work well here.\n",
    "\n",
    "- Light sensor values (S1_Light to S3_Light):\n",
    "    - Huge variation (e.g., S2_Light ranges from 0 to 258).\n",
    "    - Min-Max Scaling is a good option since it preserves relative differences and brings everything between 0 and 1.\n",
    "\n",
    "- Sound sensor values (S3_Sound, S4_Sound):\n",
    "    - Small values (0.04 - 3.67 V) but with a high standard deviation (~0.6).\n",
    "    - Standardization (Z-score) is ideal here.\n",
    "\n",
    "- CO2 (S5_CO2) and CO2 Slope (S5_CO2_Slope):\n",
    "    - Large range in CO2 (345 - 1270 PPM) and very high standard deviation (~250).\n",
    "    - CO2 slope has negative values and a large range (-6.29 to 8.98).\n",
    "    - Robust Scaling is best to reduce the effect of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for Decision Tree\n",
    "dtc_param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# Define parameter grid for KNN\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# Grid Search for Decision Tree\n",
    "dtc_grid = GridSearchCV(DecisionTreeClassifier(), dtc_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "dtc_grid.fit(X_train, y_train)\n",
    "\n",
    "# Grid Search for KNN\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "knn_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Decision Tree Parameters:\", dtc_grid.best_params_)\n",
    "print(\"Best KNN Parameters:\", knn_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUCK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Observations</th>\n",
       "      <th>Accuracy - Train</th>\n",
       "      <th>Accuracy - Test</th>\n",
       "      <th>F1 - Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Shit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996375</td>\n",
       "      <td>0.996371</td>\n",
       "      <td>0.996375</td>\n",
       "      <td>0.996389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Test Observations  Accuracy - Train  ...  F1 - Score    Recall  Precision\n",
       "0  Baseline         Shit               1.0  ...    0.996371  0.996375   0.996389\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "FUCK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Observations</th>\n",
       "      <th>Accuracy - Train</th>\n",
       "      <th>Accuracy - Test</th>\n",
       "      <th>F1 - Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Shit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997734</td>\n",
       "      <td>0.997734</td>\n",
       "      <td>0.997734</td>\n",
       "      <td>0.997767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Test Observations  Accuracy - Train  ...  F1 - Score    Recall  Precision\n",
       "0  Baseline         Shit               1.0  ...    0.997734  0.997734   0.997767\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "FUCK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Observations</th>\n",
       "      <th>Accuracy - Train</th>\n",
       "      <th>Accuracy - Test</th>\n",
       "      <th>F1 - Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Shit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994563</td>\n",
       "      <td>0.994539</td>\n",
       "      <td>0.994563</td>\n",
       "      <td>0.994561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Test Observations  Accuracy - Train  ...  F1 - Score    Recall  Precision\n",
       "0  Baseline         Shit               1.0  ...    0.994539  0.994563   0.994561\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "FUCK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Observations</th>\n",
       "      <th>Accuracy - Train</th>\n",
       "      <th>Accuracy - Test</th>\n",
       "      <th>F1 - Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Shit</td>\n",
       "      <td>0.999547</td>\n",
       "      <td>0.996375</td>\n",
       "      <td>0.99637</td>\n",
       "      <td>0.996375</td>\n",
       "      <td>0.996375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Test Observations  Accuracy - Train  ...  F1 - Score    Recall  Precision\n",
       "0  Baseline         Shit          0.999547  ...     0.99637  0.996375   0.996375\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "FUCK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Observations</th>\n",
       "      <th>Accuracy - Train</th>\n",
       "      <th>Accuracy - Test</th>\n",
       "      <th>F1 - Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Shit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.999856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Test Observations  ...    Recall  Precision\n",
       "0  RandomOverSampler         Shit  ...  0.999856   0.999856\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "FUCK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Observations</th>\n",
       "      <th>Accuracy - Train</th>\n",
       "      <th>Accuracy - Test</th>\n",
       "      <th>F1 - Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Shit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.999856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Test Observations  ...    Recall  Precision\n",
       "0  RandomOverSampler         Shit  ...  0.999856   0.999856\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "FUCK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Observations</th>\n",
       "      <th>Accuracy - Train</th>\n",
       "      <th>Accuracy - Test</th>\n",
       "      <th>F1 - Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Shit</td>\n",
       "      <td>0.999615</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>0.999712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Test Observations  ...    Recall  Precision\n",
       "0  RandomOverSampler         Shit  ...  0.999711   0.999712\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "FUCK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Observations</th>\n",
       "      <th>Accuracy - Train</th>\n",
       "      <th>Accuracy - Test</th>\n",
       "      <th>F1 - Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Shit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996824</td>\n",
       "      <td>0.996825</td>\n",
       "      <td>0.996824</td>\n",
       "      <td>0.996831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test Observations  Accuracy - Train  ...  F1 - Score    Recall  Precision\n",
       "0  SMOTE         Shit               1.0  ...    0.996825  0.996824   0.996831\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "FUCK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Observations</th>\n",
       "      <th>Accuracy - Train</th>\n",
       "      <th>Accuracy - Test</th>\n",
       "      <th>F1 - Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Shit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99668</td>\n",
       "      <td>0.996681</td>\n",
       "      <td>0.99668</td>\n",
       "      <td>0.996685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test Observations  Accuracy - Train  ...  F1 - Score   Recall  Precision\n",
       "0  SMOTE         Shit               1.0  ...    0.996681  0.99668   0.996685\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "FUCK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Observations</th>\n",
       "      <th>Accuracy - Train</th>\n",
       "      <th>Accuracy - Test</th>\n",
       "      <th>F1 - Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Shit</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>0.996391</td>\n",
       "      <td>0.99639</td>\n",
       "      <td>0.996391</td>\n",
       "      <td>0.996392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test Observations  Accuracy - Train  ...  F1 - Score    Recall  Precision\n",
       "0  SMOTE         Shit          0.999711  ...     0.99639  0.996391   0.996392\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "FUCK\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[135]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Grid Search for Decision Tree\u001b[39;00m\n\u001b[32m     46\u001b[39m grid_model = GridSearchCV(model, params, cv=\u001b[32m5\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mgrid_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m y_pred_train = grid_model.predict(X_train)\n\u001b[32m     50\u001b[39m y_pred_test = grid_model.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/JUPYTER/JupyterML/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/JUPYTER/JupyterML/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/JUPYTER/JupyterML/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/JUPYTER/JupyterML/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/JUPYTER/JupyterML/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/JUPYTER/JupyterML/.venv/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/JUPYTER/JupyterML/.venv/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/JUPYTER/JupyterML/.venv/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Define parameter grid for Decision Tree\n",
    "dtc_param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# Define parameter grid for KNN\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Test\":[],\n",
    "    \"Observations\":[],\n",
    "    \"Accuracy - Train\":[],\n",
    "    \"Accuracy - Test\":[],\n",
    "    \"F1 - Score\":[],\n",
    "    \"Recall\":[],\n",
    "    \"Precision\":[]\n",
    "})\n",
    "\n",
    "classifiers = [\n",
    "    {\"model\": DecisionTreeClassifier(), \"params\": dtc_param_grid},\n",
    "    {\"model\": KNeighborsClassifier(), \"params\": knn_param_grid},\n",
    "]\n",
    "\n",
    "for test in classifiers:\n",
    "    model = test[\"model\"]\n",
    "    params = test[\"params\"]\n",
    "\n",
    "    for test in test_data:\n",
    "        print(\"FUCK\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(test[\"data\"].drop(columns=['Room_Occupancy_Count']), test[\"data\"]['Room_Occupancy_Count'], test_size=0.25, random_state=123)\n",
    "\n",
    "        # Grid Search for Decision Tree\n",
    "        grid_model = GridSearchCV(model, params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "        grid_model.fit(X_train, y_train)\n",
    "        y_pred_train = grid_model.predict(X_train)\n",
    "        y_pred_test = grid_model.predict(X_test)\n",
    "        \n",
    "        accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        precision = precision_score(y_test, y_pred_test, average='weighted')  # Use 'macro' or 'weighted' for multi-class\n",
    "        recall = recall_score(y_test, y_pred_test, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "        ndf = pd.DataFrame([{\n",
    "            \"Test\":f\"{test[\"method\"]}\",\n",
    "            \"Observations\":f\"{\"Shit\"}\",\n",
    "            \"Accuracy - Train\":accuracy_train,\n",
    "            \"Accuracy - Test\":accuracy_test,\n",
    "            \"F1 - Score\":f1,\n",
    "            \"Recall\":recall,\n",
    "            \"Precision\":precision\n",
    "        }])\n",
    "\n",
    "        display(ndf)\n",
    "\n",
    "        print(grid_model.best_params_)\n",
    "\n",
    "        df = pd.concat([df, ndf], ignore_index=True)\n",
    "\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP0lozUQb04uqOTjFEy2kRL",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
